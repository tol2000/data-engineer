{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прием и обработка твитов микробатчем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StringType, IntegerType, TimestampType}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.toree.kernel.api\n",
    "import java.util.Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelPath = /home/jovyan/models/spark-ml-model\n",
       "model = pipeline_e3869da6fdc9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e3869da6fdc9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelPath = \"/home/jovyan/models/spark-ml-model\"\n",
    "val model = PipelineModel.load(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем схему и инициируем потоковый датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputStreamPath = /home/jovyan/work/events-stream\n",
       "modelPath = /home/jovyan/models/spark-ml-model\n",
       "dataSchema = StructType(StructField(tweet,StringType,true), StructField(hiddentargetclue,IntegerType,true), StructField(arrived_key,StringType,true), StructField(timestamp,TimestampType,true))\n",
       "inputDF = [tweet: string, hiddentargetclue: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[tweet: string, hiddentargetclue: int ... 2 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputStreamPath = \"/home/jovyan/work/events-stream\"\n",
    "val modelPath = \"/home/jovyan/models/spark-ml-model\"\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"tweet\", StringType)\n",
    "    .add(\"hiddentargetclue\", IntegerType)\n",
    "    .add(\"arrived_key\", StringType)\n",
    "    .add(\"timestamp\", TimestampType)\n",
    "\n",
    "val inputDF = spark\n",
    "    .readStream\n",
    "    .schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .json(inputStreamPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глобальная переменная для удобства просмотра датасета в отдельной ячейке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "globDF: org.apache.spark.sql.DataFrame = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "var globDF:DataFrame = null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внимание!\n",
    "- К сожалению, я не нашел внятной доки по апи ядра toree, чтобы нормально выводить оперативно изменяющийся датасет в этом ноутбуке\n",
    "- В связи с этим см. след. пункт\n",
    "- В блоке приема твитов ниже вывод датасета для удобства просмотра осуществляется через глобальную переменную globDF, которая просматривается при помощи выполнения блока, следующего за приемом твитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Микробатч приема твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-27T21:30:22.598Z - loaded from the events stream 2 times\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function2>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7, IntegerType)))\n",
       "fRuns = 0\n",
       "stream = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@69d1b32e\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@69d1b32e"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-27T21:30:31.496Z - loaded from the events stream 6 times\r"
     ]
    }
   ],
   "source": [
    "// Определяем udf для получения probability по 0 и 1\n",
    "val getProbability =\n",
    "    udf(\n",
    "        (prediction: org.apache.spark.ml.linalg.Vector, pos: Integer) =>\n",
    "        {\n",
    "            prediction(pos)\n",
    "        }\n",
    "    )\n",
    "\n",
    "var fRuns = 0\n",
    "\n",
    "// Микробатч для вывода результата предсказания\n",
    "// Выводится вероятность негативного твита\n",
    "// В задании написано, что это последняя колонка, но она здесь вроде первая (в позиции 0)\n",
    "val stream = inputDF.writeStream.foreachBatch {\n",
    "    (batchDF: DataFrame, batchId: Long) => {\n",
    "        try {\n",
    "            fRuns += 1\n",
    "            print(s\"${Calendar.getInstance().toInstant} - loaded from the events stream $fRuns times\"+13.toChar)\n",
    "            // Применяем модель и получаем соотв. датасет с предсказаниями\n",
    "            globDF = \n",
    "                model.transform(batchDF)\n",
    "                    .select(\n",
    "                        $\"arrived_key\",\n",
    "                        $\"timestamp\",\n",
    "                        $\"tweet\",\n",
    "                        // $\"hiddentargetclue\",\n",
    "                        (getProbability($\"probability\",lit(0))).alias(\"Negative Probability\")\n",
    "                    )\n",
    "        } catch {\n",
    "            case e:Throwable => {\n",
    "                print(e.getMessage.replaceAll(\"\\n\",\" \"))\n",
    "                print(13.toChar)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блок просмотра результата\n",
    "- Этот блок предназначен для просмотра результата потоковой обработки твитов и применения модели из предыдущего блока\n",
    "- Каждый раз при выполнении этого блока будет выводиться оперативное состояние датасета из блока выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>arrived_key</th><th>timestamp</th><th>tweet</th><th>Negative Probability</th></tr><tr><td>2020-01-27 21:30:20.831 - 09177</td><td>2020-01-27 23:30:20.831</td><td>Gardening faery does not exist.  </td><td>0.49339774930100216</td></tr><tr><td>2020-01-27 21:30:20.831 - 22574</td><td>2020-01-27 23:30:20.831</td><td>@Fyt1247 i heard ure officially gay now   Battty gyaaal</td><td>0.49862572525421706</td></tr><tr><td>2020-01-27 21:30:20.831 - 26613</td><td>2020-01-27 23:30:20.831</td><td>@mileycyrus YOU WONNN???? Ayayay congrats!! You deserve it  Im from Indonesia and we have different time. So, I didnt watch you. Sorry </td><td>0.5022639106298054</td></tr><tr><td>2020-01-27 21:30:20.831 - 35416</td><td>2020-01-27 23:30:20.831</td><td>DAMN ALLERGIES! its so itchy. :|:| i think its just an insect bite tho. but its so itchy!!!! i hate it. </td><td>0.542921695640404</td></tr><tr><td>2020-01-27 21:30:20.831 - 46796</td><td>2020-01-27 23:30:20.831</td><td>@xSilja I am pretty sure you are better than me. I would never be anywhere near getting 10. I suck so bad and my teacher is wicked </td><td>0.5059547803599953</td></tr><tr><td>2020-01-27 21:30:20.831 - 58875</td><td>2020-01-27 23:30:20.831</td><td>I feel like I don't know any of this stuff.  </td><td>0.5098724112223645</td></tr><tr><td>2020-01-27 21:30:20.831 - 77773</td><td>2020-01-27 23:30:20.831</td><td>my baby is getting old  he had a breathing attack and scared me. makes me want to cry.</td><td>0.5485581169759849</td></tr><tr><td>2020-01-27 21:30:20.831 - 78685</td><td>2020-01-27 23:30:20.831</td><td>I can't take it anymore  I really need a memory stick</td><td>0.5233636405528105</td></tr><tr><td>2020-01-27 21:30:20.831 - 11235</td><td>2020-01-27 23:30:20.831</td><td>@smallerrock It is very good! I was impressed </td><td>0.4994158314449909</td></tr><tr><td>2020-01-27 21:30:20.831 - 12002</td><td>2020-01-27 23:30:20.831</td><td>@TheRealLuis one i wrote and post in YouTube </td><td>0.5152059536821942</td></tr><tr><td>2020-01-27 21:30:20.831 - 13177</td><td>2020-01-27 23:30:20.831</td><td>Tried a different route to work today! Well impressed! </td><td>0.5118651335329394</td></tr><tr><td>2020-01-27 21:30:20.831 - 14134</td><td>2020-01-27 23:30:20.831</td><td>@xSteffiix haha x) I think we're not alone ... </td><td>0.5043731209856099</td></tr></table>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dataframe --limit=100\n",
    "globDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Останов чтения потока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "globDF: org.apache.spark.sql.DataFrame = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "globDF = null\n",
    "stream.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
