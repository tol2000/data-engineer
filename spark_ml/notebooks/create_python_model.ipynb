{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tolic's notes\n",
    "[twitter sentiment description](http://help.sentiment140.com/for-students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Скачаем датасет данных с Twitter Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /home/jovyan/data\n",
    "! mkdir -p /home/jovyan/models\n",
    "! echo Dirs created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip -O /home/jovyan/data/sentiment.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /home/jovyan/data && unzip sentiment.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -la /home/jovyan/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 5 /home/jovyan/data/training.1600000.processed.noemoticon.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Читаем датасет с помощью Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark context started\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('twitter-sentiment').getOrCreate()\n",
    "\n",
    "print(\"Spark context started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     1|800000|\n",
      "|     0|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"raw_timestamp\", StringType(), True),\n",
    "    StructField(\"query_status\", StringType(), True),\n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True)\n",
    "])\n",
    "    \n",
    "data_path = \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "raw_sentiment = spark.read.csv(data_path,header=False,schema=schema) \\\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as target\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.13.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size is: 16086\n"
     ]
    }
   ],
   "source": [
    "raw_sentiment_sample = raw_sentiment.sample(fraction=0.01,withReplacement=False,seed=42).toPandas()\n",
    "X, y = raw_sentiment_sample[\"tweet\"], raw_sentiment_sample[\"target\"]\n",
    "\n",
    "print(\"Dataset size is: %i\" % X.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@mangaaa I hope they will increase the capacit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@mercedesashley Damn! The grind is inspiration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got my presentation done, 23 slides done....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>http://is.gd/r8Zf,  http://is.gd/r8Zy, and  ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                              tweet\n",
       "0       0                                        Need a hug \n",
       "1       0  @mangaaa I hope they will increase the capacit...\n",
       "2       0  @mercedesashley Damn! The grind is inspiration...\n",
       "3       0  Just got my presentation done, 23 slides done....\n",
       "4       0  http://is.gd/r8Zf,  http://is.gd/r8Zy, and  ht..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sentiment_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': (5, 8),\n",
      " 'clf__n_estimators': (40, 60, 100),\n",
      " 'tfidf__max_df': (0.5, 0.75, 1.0)}\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 131.245s\n",
      "\n",
      "Best score: 0.662\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 8\n",
      "\tclf__n_estimators: 100\n",
      "\ttfidf__max_df: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "from sentiment_model import pipeline, parameters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def save_model(model,model_path):\n",
    "    with open(model_path,'wb') as buffer:\n",
    "        pkl.dump(model,buffer)\n",
    "\n",
    "def read_model(model_path):\n",
    "    with open(model_path,'rb') as buffer:\n",
    "        return pkl.load(buffer)\n",
    "\n",
    "model_path = \"/home/jovyan/models/tweet_sentiment.mdl\"\n",
    "save_model(grid_search.best_estimator_,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=<function preprocessor at 0x7f0116d2ac80>,\n",
       "                                 smooth_idf=True, stop_words=None,\n",
       "                                 strip_accents=None,...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=8,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_object = read_model(model_path)\n",
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_object.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f010fcbaba8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAAI/CAYAAAAYxjIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcv0lEQVR4nO3df6zlaX3Q8ffH3ZZuqUQaZCS7pIu6sRZWYzsitaaZhFY2pXFpLHENFdAmG5H+0KzRxT/sH4YEEzEtidBsWgVilaz0Bxu3tCXoxJgQ6NJWt0Cxm7LCylraJm3ZRqmDj3/MU3u7OzB3dmbunR+vV3Jzz3nO93vOcyb77Pfe9z3fc2atFQAAAAD8oeOeAAAAAABXBqEIAAAAgEooAgAAAGATigAAAACohCIAAAAANqEIAAAAgKpuPO4JnM9znvOcdeuttx754/7O7/xOz3zmM4/8cYGLY+3C1ce6hauTtQtXH+uWgz784Q//+lrrjz55/IoPRbfeemsPPfTQkT/u6dOnO3Xq1JE/LnBxrF24+li3cHWyduHqY91y0Mz893ONO/UMAAAAgEooAgAAAGATigAAAACohCIAAAAANqEIAAAAgEooAgAAAGATigAAAACohCIAAAAANqEIAAAAgEooAgAAAGATigAAAACohCIAAAAANqEIAAAAgEooAgAAAGATigAAAACohCIAAAAANqEIAAAAgEooAgAAAGATigAAAACohCIAAAAANqEIAAAAgEooAgAAAGATigAAAACohCIAAAAAthuPewIAAHC53Hrvg8c9hWvWPbef6bVP89/30Te9/BLPBoBLxSuKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYDtUKJqZvzczH5mZX5yZfzszXzYzXzkz75uZX97fn31g+zfMzCMz8/GZedmB8a+bmYf3bW+ZmbkcTwoAAACAC3feUDQzN1ffU51ca72ouqG6q7q3ev9a67bq/ft6M/M1+/YXVndUb52ZG/bdva26u7ptf91xSZ8NAAAAAE/bYU89u7G6aWZurL68+nR1Z/WOffs7qlfsy3dW71prfW6t9YnqkerFM/O86llrrQ+stVb1zgP7AAAAAHDMzhuK1lr/o/pn1Serx6vfWmv9THVirfX43ubx6rl7l5urTx24i8f22M378pPHAQAAALgC3Hi+DfZ7D91ZvaD6zerfzcx3fLFdzjG2vsj4uR7z7s6eotaJEyc6ffr0+aZ5yT3xxBPH8rjAxbF24epj3XI53XP7meOewjXrxE1P/9/Xmofj4ZjLYZw3FFXfVH1irfVrVTPzY9VfrH51Zp631np8n1b2mb39Y9XzD+x/S2dPVXtsX37y+FOste6r7qs6efLkOnXq1KGf0KVy+vTpjuNxgYtj7cLVx7rlcnrtvQ8e9xSuWffcfqY3P3yYXyee6tFXnbq0kwEOxTGXwzjMexR9snrJzHz5/pSyl1Yfqx6oXrO3eU31nn35gequmXnGzLygs29a/aF9etpnZ+Yl+35efWAfAAAAAI7Zef8EsNb64My8u/q56kz18519tc9XVPfPzHd2Nia9cm//kZm5v/ro3v71a63P77t7XfX26qbqvfsLAAAAgCvAoV4rutb6vur7njT8uc6+uuhc27+xeuM5xh+qXnSBcwQAAADgCBzm1DMAAAAArgNCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAdqhQNDN/ZGbePTO/NDMfm5mvn5mvnJn3zcwv7+/PPrD9G2bmkZn5+My87MD4183Mw/u2t8zMXI4nBQAAAMCFO+wrin6g+qm11ldXf7b6WHVv9f611m3V+/f1ZuZrqruqF1Z3VG+dmRv2/byturu6bX/dcYmeBwAAAAAX6byhaGaeVX1j9cNVa63fXWv9ZnVn9Y692TuqV+zLd1bvWmt9bq31ieqR6sUz87zqWWutD6y1VvXOA/sAAAAAcMwO84qiP179WvWvZubnZ+aHZuaZ1Ym11uNV+/tz9/Y3V586sP9je+zmffnJ4wAAAABcAW485DZfW333WuuDM/MD7dPMvoBzve/Q+iLjT72Dmbs7e4paJ06c6PTp04eY5qX1xBNPHMvjAhfH2oWrj3XL5XTP7WeOewrXrBM3Pf1/X2sejodjLodxmFD0WPXYWuuD+/q7OxuKfnVmnrfWenyfVvaZA9s//8D+t1Sf3uO3nGP8KdZa91X3VZ08eXKdOnXqcM/mEjp9+nTH8bjAxbF24epj3XI5vfbeB497Ctese24/05sfPsyvE0/16KtOXdrJAIfimMthnPfUs7XW/6w+NTN/ag+9tPpo9UD1mj32muo9+/ID1V0z84yZeUFn37T6Q/v0tM/OzEv2p529+sA+AAAAAByzw/4J4LurH5mZL61+pfqbnY1M98/Md1afrF5Ztdb6yMzc39mYdKZ6/Vrr8/t+Xle9vbqpeu/+AgAAAOAKcKhQtNb6herkOW566RfY/o3VG88x/lD1oguZIAAAAABH4zCfegYAAADAdUAoAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYDh2KZuaGmfn5mfn3+/pXzsz7ZuaX9/dnH9j2DTPzyMx8fGZedmD862bm4X3bW2ZmLu3TAQAAAODpupBXFH1v9bED1++t3r/Wuq16/77ezHxNdVf1wuqO6q0zc8Pe523V3dVt++uOi5o9AAAAAJfMoULRzNxSvbz6oQPDd1bv2JffUb3iwPi71lqfW2t9onqkevHMPK961lrrA2utVb3zwD4AAAAAHLPDvqLo+6t/UP3fA2Mn1lqPV+3vz93jN1efOrDdY3vs5n35yeMAAAAAXAFuPN8GM/Ot1WfWWh+emVOHuM9zve/Q+iLj53rMuzt7ilonTpzo9OnTh3jYS+uJJ544lscFLo61C1cf65bL6Z7bzxz3FK5ZJ256+v++1jwcD8dcDuO8oaj6huqvzMy3VF9WPWtm/nX1qzPzvLXW4/u0ss/s7R+rnn9g/1uqT+/xW84x/hRrrfuq+6pOnjy5Tp06dfhndImcPn2643hc4OJYu3D1sW65nF5774PHPYVr1j23n+nNDx/m14mnevRVpy7tZIBDcczlMM576tla6w1rrVvWWrd29k2q/8Na6zuqB6rX7M1eU71nX36gumtmnjEzL+jsm1Z/aJ+e9tmZecn+tLNXH9gHAAAAgGP29P4EcNabqvtn5jurT1avrFprfWRm7q8+Wp2pXr/W+vze53XV26ubqvfuLwAAAACuABcUitZap6vT+/JvVC/9Atu9sXrjOcYfql50oZMEAAAA4PI77KeeAQAAAHCNE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgu/G4JwAAAFxfbr33weOeAk/y6JteftxTAK4QXlEEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQFU3HvcEAACuFbfe++BxTwEA4KJ4RREAAAAAlVAEAAAAwCYUAQAAAFAJRQAAAABsQhEAAAAAlVAEAAAAwCYUAQAAAFAJRQAAAABsQhEAAAAAlVAEAAAAwCYUAQAAAFAJRQAAAABsQhEAAAAAlVAEAAAAwCYUAQAAAFAJRQAAAABsQhEAAAAAlVAEAAAAwCYUAQAAAFAJRQAAAABs5w1FM/P8mfmPM/OxmfnIzHzvHv/KmXnfzPzy/v7sA/u8YWYemZmPz8zLDox/3cw8vG97y8zM5XlaAAAAAFyow7yi6Ex1z1rrT1cvqV4/M19T3Vu9f611W/X+fb19213VC6s7qrfOzA37vt5W3V3dtr/uuITPBQAAAICLcN5QtNZ6fK31c/vyZ6uPVTdXd1bv2Ju9o3rFvnxn9a611ufWWp+oHqlePDPPq5611vrAWmtV7zywDwAAAADH7ILeo2hmbq3+XPXB6sRa6/E6G5Oq5+7Nbq4+dWC3x/bYzfvyk8cBAAAAuALceNgNZ+Yrqh+t/u5a67e/yNsLneuG9UXGz/VYd3f2FLVOnDjR6dOnDzvNS+aJJ544lscFLo61C1efa2nd3nP7meOeAhyZEzf5b/5acq38f5gv7lo65nL5HCoUzcyXdDYS/cha68f28K/OzPPWWo/v08o+s8cfq55/YPdbqk/v8VvOMf4Ua637qvuqTp48uU6dOnW4Z3MJnT59uuN4XODiWLtw9bmW1u1r733wuKcAR+ae28/05ocP/XdnrnCPvurUcU+BI3AtHXO5fA7zqWdT/XD1sbXWPz9w0wPVa/bl11TvOTB+18w8Y2Ze0Nk3rf7QPj3tszPzkn2frz6wDwAAAADH7DB/AviG6m9UD8/ML+yxf1S9qbp/Zr6z+mT1yqq11kdm5v7qo539xLTXr7U+v/d7XfX26qbqvfsLAAAAgCvAeUPRWus/d+73F6p66RfY543VG88x/lD1oguZIAAAAABH44I+9QwAAACAa5dQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVHXjcU8AALhwt9774HFP4ZK55/YzvfYaej4AAFczrygCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoKobj3sCAAAAHK9b733wuKfAOTz6ppcf9xS4DnlFEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAACVUAQAAADAJhQBAAAAUAlFAAAAAGxCEQAAAABV3XjcEwDgynfrvQ8e9xQAAIAj4BVFAAAAAFRCEQAAAADbkYeimbljZj4+M4/MzL1H/fgAAAAAnNuRvkfRzNxQ/Yvqm6vHqp+dmQfWWh89ynkAAADAle5Sv0/kPbef6bXee/KiPPqmlx/3FC67o35F0YurR9Zav7LW+t3qXdWdRzwHAAAAAM7hqD/17ObqUweuP1b9hSOeA3AFu9i/mvgrCQAAwNN31KFozjG2nrLRzN3V3fvqEzPz8cs6q3N7TvXrx/C4wEX4HmsXrjrWLVydrF24+li3F2/+6XHP4JL6qnMNHnUoeqx6/oHrt1SffvJGa637qvuOalLnMjMPrbVOHuccgAtn7cLVx7qFq5O1C1cf65bDOOr3KPrZ6raZecHMfGl1V/XAEc8BAAAAgHM40lcUrbXOzMx3VT9d3VD9y7XWR45yDgAAAACc21GfetZa6yernzzqx30ajvXUN+Bps3bh6mPdwtXJ2oWrj3XLec1aT3kvaQAAAACuQ0f9HkUAAAAAXKGuy1A0M3fMzMdn5pGZufcct985M/91Zn5hZh6amb904LZHZ+bh37vtaGcO16/zrdsD2/35mfn8zHz7he4LXHoXuXYdc+EYHOJn5VMz81t7bf7CzPzjw+4LXD4XuXYdc/n/rrtTz2bmhuq/Vd9cPdbZT2L762utjx7Y5iuq31lrrZn5M9X9a62v3rc9Wp1ca/36kU8erlOHWbcHtntf9b87+2b57z7svsCldzFrd48/mmMuHKlD/qx8qvr7a61vvdB9gcvjYtbuvu3RHHPZrsdXFL24emSt9Strrd+t3lXdeXCDtdYT6/cL2jOr66umwZXnvOt2++7qR6vPPI19gUvvYtYucDwu5rjpmAvHx/rjkrkeQ9HN1acOXH9sj/0BM/NtM/NL1YPV3zpw06p+ZmY+PDN3X9aZAr/nvOt2Zm6uvq36wQvdF7hsLmbtlmMuHIfDHje/fmb+y8y8d2ZeeIH7ApfexazdcszlgBuPewLHYM4x9pRXDK21frz68Zn5xuqfVN+0b/qGtdanZ+a51ftm5pfWWv/p8k0X6HDr9vurf7jW+vzMH9j8UGseuCwuZu2WYy4ch8Os25+rvmqt9cTMfEv1E9Vth9wXuDwuZu2WYy4HXI+vKHqsev6B67dUn/5CG+/F8Sdm5jn7+qf3989UP97Zl/gBl9dh1u3J6l37/Opvr946M6845L7A5XExa9cxF47HedftWuu311pP7Ms/WX3J/lnZMReOz8WsXcdc/oDrMRT9bHXbzLxgZr60uqt64OAGM/MnZ/9Zc2a+tvrS6jdm5pkz84f3+DOrv1z94pHOHq5P5123a60XrLVuXWvdWr27+jtrrZ84zL7AZfO0165jLhybw/ys/McO/Kz84s7+TvEbh9kXuGye9tp1zOXJrrtTz9ZaZ2bmu6qfrm7o7KerfGRm/va+/Qerv1q9emb+T/W/qr+2PwHtRGdPR6uz/3b/Zq31U8fyROA6csh1e0H7HsW84Xp3MWu3csyFY3DIdfvt1etm5kxnf1a+a38QjGMuHJOLWbt+z+XJ5vc/3AsAAACA69n1eOoZAAAAAOcgFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAFX9P/5nyyccpGVAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "pd.Series(model_object.predict_proba(X)[:,1]).hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tolic's additional experiments\n",
    "# ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toldf = spark.read.csv(data_path,header=False,schema=schema)\n",
    "#toldf.where(\"tweet like '%Need%a%hug%'\").select(\"id\", \"tweet\").show(20,150)\n",
    "toldf = toldf.selectExpr(\"(case when target=4 then 1 else 0 end) as target\",\"id\",\"raw_timestamp\",\"query_status\",\"author\",\"tweet\")\n",
    "toldf_sample = toldf.sample(fraction=0.01,withReplacement=False,seed=42).toPandas()\n",
    "toldf_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        dict\n",
       "\u001b[0;31mString form:\u001b[0m {'memory': None, 'steps': [('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error= <...>  'clf__oob_score': False, 'clf__random_state': None, 'clf__verbose': 0, 'clf__warm_start': False}\n",
       "\u001b[0;31mLength:\u001b[0m      43\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "dict() -> new empty dictionary\n",
       "dict(mapping) -> new dictionary initialized from a mapping object's\n",
       "    (key, value) pairs\n",
       "dict(iterable) -> new dictionary initialized as if via:\n",
       "    d = {}\n",
       "    for k, v in iterable:\n",
       "        d[k] = v\n",
       "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
       "    in the keyword argument list.  For example:  dict(one=1, two=2)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Need a hug \n",
       "1        @mangaaa I hope they will increase the capacit...\n",
       "2        @mercedesashley Damn! The grind is inspiration...\n",
       "3        Just got my presentation done, 23 slides done....\n",
       "4        http://is.gd/r8Zf,  http://is.gd/r8Zy, and  ht...\n",
       "                               ...                        \n",
       "16081                            TVMA is now on Twitter!! \n",
       "16082                                      to be with you \n",
       "16083    loves visitors so if you are goin to the Aeros...\n",
       "16084    @BrunoFigueiredo @ppinheiro76 @pedrocs Top Gea...\n",
       "16085                 @Bruno108 I would like some please! \n",
       "Name: tweet, Length: 16086, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16086\n",
      "(16086, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.size)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4653\n"
     ]
    }
   ],
   "source": [
    "def predict01(ind):\n",
    "    if a[ind,0]>a[ind,1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "qnty = 0\n",
    "for i in range(10,a.shape[0]):\n",
    "    pre = predict01(i)\n",
    "    if pre != y[i]:\n",
    "        qnty = qnty+1\n",
    "print(qnty)\n",
    "    #print(X[i])\n",
    "    #print(\"\\t\", \"origin: \",y[i], \"\\t\", \"predict: \",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16086"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
