{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------+\n",
      "|label|                                                                                                              tweet|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------+\n",
      "|    0|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|    0|    is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!|\n",
      "|    0|                          @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "|    0|                                                                     my whole body feels itchy and like its on fire|\n",
      "|    0|     @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|                                                                                                                                   tweet|\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    1|                                                                                             I LOVE @Health4UandPets u guys r the best!!|\n",
      "|    1|                                                                im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!|\n",
      "|    1|@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart.|\n",
      "|    1|                                Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup|\n",
      "|    1|                                                                                          @LovesBrooklyn2 he has that effect on everyone|\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath = /home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val dataPath= \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "// Load and parse the data file, converting it to a DataFrame.\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"trim(tweet) as tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show\n",
    "raw_sentiment.where(\"label=0\").show(5,150)\n",
    "raw_sentiment.where(\"label=1\").show(5,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_930362eb7679\n",
       "hashingTF = hashingTF_899fa58d4332\n",
       "labelIndexer = strIdx_40fd7cef6c8f\n",
       "featureIndexer = vecIdx_99bb16a9b424\n",
       "rf = rfc_cdb1e3df91b9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "labelConverter: org.apache.spark.ml.feature.Ind...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "rfc_cdb1e3df91b9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "\n",
    "// Без токенайзера в рандомном лесе тоже, как я понял, не обойтись...\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "// Как не обойтись и без хэш-формирования фичей, т.е. индексатору фичей нужны на входе фичи, а не слова.\n",
    "// Иными словами, тут мы выделяем из текста фичи\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "// Запускаем индексацию меток по всему датасету\n",
    "// Как я понял, он требует весь raw_sentiment, чтобы проиндексировать все возможные метки.\n",
    "val labelIndexer = new StringIndexer()\n",
    "  .setInputCol(\"label\")\n",
    "  .setOutputCol(\"indexedLabel\")\n",
    "  .fit(raw_sentiment)\n",
    "\n",
    "// Индексируем полученные фичи, выделяя их категории\n",
    "// Как я понял, это некоторые группы предопределенных значений вроде\n",
    "//     фича1:(открыто, закрыто), фича2:(короткий, средний, длинный), фича3:(хороший, плохой, никакой) и т.д...\n",
    "val featureIndexer = new VectorIndexer()\n",
    "  .setInputCol(\"features\")\n",
    "  .setOutputCol(\"indexedFeatures\")\n",
    "  .setMaxCategories(4)\n",
    "\n",
    "// Собственно, метод тренировки типа \"случайный лес\"\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"indexedLabel\")\n",
    "  .setFeaturesCol(\"indexedFeatures\")\n",
    "  .setNumTrees(10)\n",
    "\n",
    "// Восстанавливаем читаемые значения меток из какого-то внутреннего формата, вектора...\n",
    "val labelConverter = new IndexToString()\n",
    "  .setInputCol(\"prediction\")\n",
    "  .setOutputCol(\"predictedLabel\")\n",
    "  .setLabels(labelIndexer.labels)\n",
    "\n",
    "// Объединяем все это дело в пайплайн...\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, labelIndexer, featureIndexer, rf, labelConverter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Будем тренировать не на 70%, как предлагает документация, а на 100%, как на лекции )\n",
    "// Split the data into training and test sets (30% held out for testing).\n",
    "// val Array(trainingData, testData) = raw_sentiment.randomSplit(Array(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_8c796ec229fd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_8c796ec229fd"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Тренируем модель, попутно запуская в этом же пайплайне необходимые индексирования\n",
    "val model = pipeline.fit(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelPath = /home/jovyan/models/spark-ml-model\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "/home/jovyan/models/spark-ml-model"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Путь к модели\n",
    "val modelPath = \"/home/jovyan/models/spark-ml-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Записываем модель для последующего применения в apply_model\n",
    "model.write.overwrite().save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel = pipeline_e3869da6fdc9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e3869da6fdc9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Считываем модель для проверки\n",
    "val sameModel = PipelineModel.load(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictionsDF = [label: int, tweet: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 8 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Применяем модель и получаем соотв. датасет с предсказаниями\n",
    "val predictionsDF = sameModel.transform(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------------+---------------+------------+---------------+---------------+---------------+----------+--------------+\n",
      "|label|          tweet|          words|       features|indexedLabel|indexedFeatures|  rawPrediction|    probability|prediction|predictedLabel|\n",
      "+-----+---------------+---------------+---------------+------------+---------------+---------------+---------------+----------+--------------+\n",
      "|    0|@switchfoot ...|[@switchfoot...|(1000,[7,14,...|         0.0|(1000,[7,14,...|[8.800332775...|[0.440016638...|       1.0|             1|\n",
      "|    0|is upset tha...|[is, upset, ...|(1000,[170,1...|         0.0|(1000,[170,1...|[10.69590843...|[0.534795421...|       0.0|             0|\n",
      "|    0|@Kenichan I ...|[@kenichan, ...|(1000,[10,36...|         0.0|(1000,[10,36...|[10.98117528...|[0.549058764...|       0.0|             0|\n",
      "|    0|my whole bod...|[my, whole, ...|(1000,[82,19...|         0.0|(1000,[82,19...|[10.47277023...|[0.523638511...|       0.0|             0|\n",
      "|    0|@nationwidec...|[@nationwide...|(1000,[18,96...|         0.0|(1000,[18,96...|[9.563246607...|[0.478162330...|       1.0|             1|\n",
      "+-----+---------------+---------------+---------------+------------+---------------+---------------+---------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Смотрим на полученный датасет в целом...\n",
    "predictionsDF.show(5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|predictedLabel|label|                                   tweet|                                   words|                                features|\n",
      "+--------------+-----+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|             1|    0|@switchfoot http://twitpic.com/2y1zl ...|[@switchfoot, http://twitpic.com/2y1z...|(1000,[7,14,21,54,91,170,220,246,311,...|\n",
      "|             0|    0|is upset that he can't update his Fac...|[is, upset, that, he, can't, update, ...|(1000,[170,193,223,248,281,333,343,37...|\n",
      "|             0|    0|@Kenichan I dived many times for the ...|[@kenichan, i, dived, many, times, fo...|(1000,[10,36,77,188,207,248,329,338,3...|\n",
      "|             0|    0|my whole body feels itchy and like it...|[my, whole, body, feels, itchy, and, ...|(1000,[82,191,296,330,333,648,841,903...|\n",
      "|             1|    0|@nationwideclass no, it's not behavin...|[@nationwideclass, no,, it's, not, be...|(1000,[18,96,130,173,248,329,352,380,...|\n",
      "|             1|    0|            @Kwesidei not the whole crew|      [@kwesidei, not, the, whole, crew]|(1000,[18,223,710,758,903],[1.0,1.0,1...|\n",
      "|             1|    0|                              Need a hug|                          [need, a, hug]|       (1000,[48,170,537],[1.0,1.0,1.0])|\n",
      "|             1|    0|@LOLTrish hey  long time no see! Yes....|[@loltrish, hey, , long, time, no, se...|(1000,[139,157,170,230,253,346,372,38...|\n",
      "|             0|    0|     @Tatiana_K nope they didn't have it|[@tatiana_k, nope, they, didn't, have...|(1000,[48,234,299,432,495,748],[1.0,1...|\n",
      "|             1|    0|                @twittera que me muera ?|          [@twittera, que, me, muera, ?]|(1000,[161,324,471,490,976],[1.0,1.0,...|\n",
      "|             1|    1|I LOVE @Health4UandPets u guys r the ...|[i, love, @health4uandpets, u, guys, ...|(1000,[216,240,329,401,526,570,681,71...|\n",
      "|             0|    1|im meeting up with one of my besties ...|[im, meeting, up, with, one, of, my, ...|(1000,[26,29,44,86,120,128,238,343,37...|\n",
      "|             1|    1|@DaRealSunisaKim Thanks for the Twitt...|[@darealsunisakim, thanks, for, the, ...|(1000,[7,19,36,135,147,170,184,230,32...|\n",
      "|             1|    1|Being sick can be really cheap when i...|[being, sick, can, be, really, cheap,...|(1000,[76,196,263,310,372,374,388,425...|\n",
      "|             1|    1|@LovesBrooklyn2 he has that effect on...|[@lovesbrooklyn2, he, has, that, effe...|(1000,[36,82,580,760,793,893,997],[1....|\n",
      "|             1|    1|@ProductOfFear You can tell him that ...|[@productoffear, you, can, tell, him,...|(1000,[1,36,201,230,307,310,329,343,3...|\n",
      "|             1|    1|@r_keith_hill Thans for your response...|[@r_keith_hill, thans, for, your, res...|(1000,[36,56,57,188,263,340,373,467,5...|\n",
      "|             1|    1|@KeepinUpWKris I am so jealous, hope ...|[@keepinupwkris, i, am, so, jealous,,...|(1000,[0,157,170,173,237,240,260,263,...|\n",
      "|             1|    1|@tommcfly ah, congrats mr fletcher fo...|[@tommcfly, ah,, congrats, mr, fletch...|(1000,[36,272,318,574,602,622,711,791...|\n",
      "|             1|    1|@e4VoIP I RESPONDED  Stupid cat is he...|[@e4voip, i, responded, , stupid, cat...|(1000,[121,281,329,372,389,412,456,47...|\n",
      "+--------------+-----+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Смотрим подробнее на результат применения модели к заранее положит. и отрицат. твитам, т.е. грубо визуально тестируем модель\n",
    "predictionsDF.where(\"label=0\").limit(10).union(predictionsDF.where(\"label=1\").limit(10)).select(\"predictedLabel\", \"label\", \"tweet\", \"words\", \"features\").show(20,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|                             probability|\n",
      "+----------------------------------------+\n",
      "| [0.4400166387510603,0.5599833612489398]|\n",
      "|[0.5347954217012693,0.46520457829873074]|\n",
      "|[0.5490587643880294,0.45094123561197075]|\n",
      "|[0.5236385117783351,0.47636148822166496]|\n",
      "| [0.4781623303690328,0.5218376696309672]|\n",
      "+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "predictionsDF.selectExpr(\"probability\").show(5,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Сохраняем в файл, чтобы помотреть детальнее...\n",
    "predictionsDF.where(\"label=0\").limit(15).union(predictionsDF.where(\"label=1\").limit(15))\n",
    "   .selectExpr(\n",
    "       \"label\",\"tweet\",\"cast (words as string)\",\"cast (features as string)\",\"cast (rawPrediction as string)\",\"cast (probability as string)\",\"prediction\"\n",
    "   )\n",
    "   .coalesce(1)\n",
    "   .write.format(\"csv\")\n",
    "   .mode(\"overwrite\")\n",
    "   .option(\"header\", \"true\")\n",
    "   .save(\"/home/jovyan/work/predictionsDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|clean_probability_0_1|label|\n",
      "+---------------------+-----+\n",
      "|          0.44 / 0.56|    0|\n",
      "|          0.53 / 0.47|    0|\n",
      "|          0.55 / 0.45|    0|\n",
      "|          0.52 / 0.48|    0|\n",
      "|          0.48 / 0.52|    0|\n",
      "|          0.49 / 0.51|    0|\n",
      "|          0.48 / 0.52|    0|\n",
      "|          0.47 / 0.53|    0|\n",
      "|          0.51 / 0.49|    0|\n",
      "|          0.48 / 0.52|    0|\n",
      "|          0.47 / 0.53|    1|\n",
      "|          0.54 / 0.46|    1|\n",
      "|          0.44 / 0.56|    1|\n",
      "|          0.47 / 0.53|    1|\n",
      "|          0.48 / 0.52|    1|\n",
      "|          0.48 / 0.52|    1|\n",
      "|          0.48 / 0.52|    1|\n",
      "|          0.43 / 0.57|    1|\n",
      "|          0.48 / 0.52|    1|\n",
      "|          0.50 / 0.50|    1|\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,StringType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,StringType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Смотрим на предсказания, выводя их в читабельном виде через udf...\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability =\n",
    "    udf(\n",
    "        (prediction: org.apache.spark.ml.linalg.Vector) =>\n",
    "        {\n",
    "            BigDecimal(prediction(0)).setScale(2, BigDecimal.RoundingMode.HALF_UP)+\n",
    "            \" / \"+\n",
    "            BigDecimal(prediction(1)).setScale(2, BigDecimal.RoundingMode.HALF_UP)\n",
    "        }\n",
    "    )\n",
    "\n",
    "predictionsDF.where(\"label=0\").limit(10).union(predictionsDF.where(\"label=1\").limit(10))\n",
    "    .select(getProbability($\"probability\").alias(\"clean_probability_0_1\"),$\"label\").show(20,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
