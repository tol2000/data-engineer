{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark context started\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('twitter-sentiment').getOrCreate()\n",
    "spark.sparkContext.addPyFile(\"/home/jovyan/work/sentiment_model.py\")\n",
    "print(\"Spark context started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddPyFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Add a .py or .zip dependency for all tasks to be executed on this\n",
       "SparkContext in the future.  The C{path} passed can be either a local\n",
       "file, a file in HDFS (or other Hadoop-supported filesystems), or an\n",
       "HTTP, HTTPS or FTP URI.\n",
       "\n",
       ".. note:: A path can be added only once. Subsequent additions of the same path are ignored.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/spark/python/pyspark/context.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sparkContext.addPyFile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     1|800000|\n",
      "|     0|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"raw_timestamp\", StringType(), True),\n",
    "    StructField(\"query_status\", StringType(), True),\n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True)\n",
    "])\n",
    "    \n",
    "data_path = \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "raw_sentiment = spark.read.csv(data_path,header=False,schema=schema) \\\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as target\",\"tweet\")\n",
    "\n",
    "\n",
    "\n",
    "raw_sentiment.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------------------------------------------------------------------------+\n",
      "|target|                                                                                               tweet|\n",
      "+------+----------------------------------------------------------------------------------------------------+\n",
      "|     0|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thir...|\n",
      "|     0|is upset that he can't update his Facebook by texting it... and might cry as a result  School tod...|\n",
      "|     0|           @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "+------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+----------------------------------------------------------------------------------------------------+\n",
      "|target|                                                                                               tweet|\n",
      "+------+----------------------------------------------------------------------------------------------------+\n",
      "|     1|                                                        I LOVE @Health4UandPets u guys r the best!! |\n",
      "|     1|                            im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!|\n",
      "|     1|@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in...|\n",
      "+------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sentiment.filter(\"target = 0\").show(3, 100)\n",
    "raw_sentiment.filter(\"target = 1\").show(3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=<function preprocessor at 0x7f656886dd90>,\n",
       "                                 smooth_idf=True, stop_words=None,\n",
       "                                 strip_accents=None,...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=8,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def read_model(model_path):\n",
    "    with open(model_path,'rb') as buffer:\n",
    "        return pkl.load(buffer)\n",
    "\n",
    "model_path = \"/home/jovyan/models/tweet_sentiment.mdl\"\n",
    "\n",
    "model_object = read_model(model_path)\n",
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/session.py:366: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------+----------------------------------------------------------------------------------------------------+\n",
      "|      proba0|      proba1|target|                                                                                                text|\n",
      "+------------+------------+------+----------------------------------------------------------------------------------------------------+\n",
      "|0.5140581764|0.4859418236|     0|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thir...|\n",
      "|0.5157546478|0.4842453522|     0|is upset that he can't update his Facebook by texting it... and might cry as a result  School tod...|\n",
      "|0.5040259259|0.4959740741|     0|           @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "|0.5096420157|0.4903579843|     0|                                                     my whole body feels itchy and like its on fire |\n",
      "|0.5040259259|0.4959740741|     0|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you al...|\n",
      "+------------+------------+------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+------------+------+----------------------------------------------------------------------------------------------------+\n",
      "|      proba0|      proba1|target|                                                                                                text|\n",
      "+------------+------------+------+----------------------------------------------------------------------------------------------------+\n",
      "|0.4809727139|0.5190272861|     1|                                                        I LOVE @Health4UandPets u guys r the best!! |\n",
      "|0.4940925645|0.5059074355|     1|                            im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!|\n",
      "|0.4867220865|0.5132779135|     1|@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in...|\n",
      "|0.5558646175|0.4441353825|     1|Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make y...|\n",
      "|0.5031811201|0.4968188799|     1|                                                     @LovesBrooklyn2 he has that effect on everyone |\n",
      "+------------+------------+------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_object_broadcast = spark.sparkContext.broadcast(model_object)\n",
    "\n",
    "def block_iterator(iterator, size):\n",
    "    bucket = list()\n",
    "    for e in iterator:\n",
    "        bucket.append(e)\n",
    "        if len(bucket) >= size:\n",
    "            yield bucket\n",
    "            bucket = list()\n",
    "    if bucket:\n",
    "        yield bucket\n",
    "\n",
    "def block_classify(iterator):\n",
    "    model = model_object_broadcast.value\n",
    "    for features in block_iterator(iterator, 10000):\n",
    "        import pandas as pd\n",
    "        import json\n",
    "        features_df = pd.DataFrame(list(features), columns=[\"target\",\"text\"])\n",
    "        pred = model.predict_proba(features_df[\"text\"])\n",
    "        res_df = features_df\n",
    "        res_df[\"proba0\"] = pred[:,0]\n",
    "        res_df[\"proba1\"] = pred[:,1]\n",
    "        for e in json.loads(res_df.to_json(orient='records')):\n",
    "            yield e\n",
    "\n",
    "predicted_df = raw_sentiment.rdd.mapPartitions(block_classify).toDF()\n",
    "\n",
    "predicted_df.where(\"target=0\").show(5,100)\n",
    "predicted_df.where(\"target=1\").show(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
