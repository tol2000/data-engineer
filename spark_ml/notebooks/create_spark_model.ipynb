{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath = /home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val dataPath= \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------------------------------------------------+\n",
      "|label|                                                                                                              tweet|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------+\n",
      "|    0|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|    0|    is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!|\n",
      "|    0|                          @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "|    0|                                                                    my whole body feels itchy and like its on fire |\n",
      "|    0|    @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. |\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|                                                                                                                                    tweet|\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    1|                                                                                             I LOVE @Health4UandPets u guys r the best!! |\n",
      "|    1|                                                                 im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!|\n",
      "|    1|@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart. |\n",
      "|    1|                                 Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup|\n",
      "|    1|                                                                                          @LovesBrooklyn2 he has that effect on everyone |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sentiment.where(\"label=0\").show(5,150)\n",
    "raw_sentiment.where(\"label=1\").show(5,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_382bb66be034\n",
       "hashingTF = hashingTF_aba39531e215\n",
       "lr = logreg_7d7c9218d06a\n",
       "pipeline = pipeline_c88e57c57142\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_c88e57c57142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "    .setMaxIter(10)\n",
    "    .setRegParam(0.001)\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_c88e57c57142\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_c88e57c57142"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel = pipeline_c88e57c57142\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_c88e57c57142"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|[-0.9010125659403...|[0.28884245921783...|       1.0|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|[1.84195706807745...|[0.86318000204742...|       0.0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|[1.56488554961140...|[0.82705328017345...|       0.0|\n",
      "|    0|my whole body fee...|[my, whole, body,...|(1000,[82,191,296...|[0.22286270195627...|[0.55548620895353...|       0.0|\n",
      "|    0|@nationwideclass ...|[@nationwideclass...|(1000,[18,96,130,...|[3.23587893775227...|[0.96216236372478...|       0.0|\n",
      "|    0|@Kwesidei not the...|[@kwesidei, not, ...|(1000,[18,223,710...|[0.33263478812924...|[0.58240032293821...|       0.0|\n",
      "|    0|         Need a hug |      [need, a, hug]|(1000,[48,170,537...|[0.09849092454166...|[0.52460284610183...|       0.0|\n",
      "|    0|@LOLTrish hey  lo...|[@loltrish, hey, ...|(1000,[139,157,17...|[-2.3498070018591...|[0.08708111418259...|       1.0|\n",
      "|    0|@Tatiana_K nope t...|[@tatiana_k, nope...|(1000,[48,234,299...|[0.82843417404240...|[0.69602374240050...|       0.0|\n",
      "|    0|@twittera que me ...|[@twittera, que, ...|(1000,[161,324,47...|[-0.1308461051980...|[0.46733506429694...|       1.0|\n",
      "|    0|spring break in p...|[spring, break, i...|(1000,[13,193,301...|[0.24494144760053...|[0.56093102965737...|       0.0|\n",
      "|    0|I just re-pierced...|[i, just, re-pier...|(1000,[307,329,47...|[-0.3966128922923...|[0.40212640024549...|       1.0|\n",
      "|    0|@caregiving I cou...|[@caregiving, i, ...|(1000,[56,202,234...|[0.69361421378522...|[0.66677044374806...|       0.0|\n",
      "|    0|@octolinz16 It it...|[@octolinz16, it,...|(1000,[126,230,32...|[0.03456400299106...|[0.50864014058827...|       0.0|\n",
      "|    0|@smarrison i woul...|[@smarrison, i, w...|(1000,[18,83,170,...|[2.98112687604561...|[0.95171418244474...|       0.0|\n",
      "|    0|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|(1000,[7,71,202,2...|[1.27944368971444...|[0.78235506522531...|       0.0|\n",
      "|    0|Hollis' death sce...|[hollis', death, ...|(1000,[2,3,18,82,...|[1.03425575867711...|[0.73774013113595...|       0.0|\n",
      "|    0|about to file taxes |[about, to, file,...|(1000,[108,388,48...|[-0.1130725419213...|[0.47176194434631...|       1.0|\n",
      "|    0|@LettyA ahh ive a...|[@lettya, ahh, iv...|(1000,[13,107,201...|[-0.9205369385656...|[0.28484850199880...|       1.0|\n",
      "|    0|@FakerPattyPattz ...|[@fakerpattypattz...|(1000,[53,102,154...|[-1.1212832164232...|[0.24577333766527...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 5 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "\n",
    "predictionsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF.where(\"label=0\").limit(15).union(predictionsDF.where(\"label=1\").limit(15))\n",
    "   .selectExpr(\n",
    "       \"label\",\"tweet\",\"cast (words as string)\",\"cast (features as string)\",\"cast (rawPrediction as string)\",\"cast (probability as string)\",\"prediction\"\n",
    "   )\n",
    "   .coalesce(1)\n",
    "   .write.format(\"csv\")\n",
    "   .mode(\"overwrite\")\n",
    "   .option(\"header\", \"true\")\n",
    "   .save(\"/home/jovyan/work/predictionsDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|clean_probability_0_1|label|\n",
      "+---------------------+-----+\n",
      "|          0.29 / 0.71|    0|\n",
      "|          0.86 / 0.14|    0|\n",
      "|          0.83 / 0.17|    0|\n",
      "|          0.56 / 0.44|    0|\n",
      "|          0.96 / 0.04|    0|\n",
      "|          0.58 / 0.42|    0|\n",
      "|          0.52 / 0.48|    0|\n",
      "|          0.09 / 0.91|    0|\n",
      "|          0.70 / 0.30|    0|\n",
      "|          0.47 / 0.53|    0|\n",
      "|          0.19 / 0.81|    1|\n",
      "|          0.69 / 0.31|    1|\n",
      "|          0.12 / 0.88|    1|\n",
      "|          0.88 / 0.12|    1|\n",
      "|          0.48 / 0.52|    1|\n",
      "|          0.22 / 0.78|    1|\n",
      "|          0.42 / 0.58|    1|\n",
      "|          0.06 / 0.94|    1|\n",
      "|          0.16 / 0.84|    1|\n",
      "|          0.54 / 0.46|    1|\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,StringType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,StringType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability =\n",
    "    udf(\n",
    "        (prediction: org.apache.spark.ml.linalg.Vector) =>\n",
    "        {\n",
    "            BigDecimal(prediction(0)).setScale(2, BigDecimal.RoundingMode.HALF_UP)+\n",
    "            \" / \"+\n",
    "            BigDecimal(prediction(1)).setScale(2, BigDecimal.RoundingMode.HALF_UP)\n",
    "        }\n",
    "    )\n",
    "\n",
    "predictionsDF.where(\"label=0\").limit(10).union(predictionsDF.where(\"label=1\").limit(10))\n",
    "    .select(getProbability($\"probability\").alias(\"clean_probability_0_1\"),$\"label\").show(20,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time 1:24:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
