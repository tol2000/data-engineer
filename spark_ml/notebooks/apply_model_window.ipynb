{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прием и обработка твитов микробатчем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StringType, IntegerType, TimestampType}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.toree.kernel.api\n",
    "import java.util.Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelPath = /home/jovyan/models/spark-ml-model\n",
       "model = pipeline_6cb85880407d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_6cb85880407d"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelPath = \"/home/jovyan/models/spark-ml-model\"\n",
    "val model = PipelineModel.load(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем схему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputStreamPath = /home/jovyan/work/events-stream\n",
       "dataSchema = StructType(StructField(tweet,StringType,true), StructField(hiddentargetclue,IntegerType,true), StructField(timestamp,TimestampType,true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(tweet,StringType,true), StructField(hiddentargetclue,IntegerType,true), StructField(timestamp,TimestampType,true))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputStreamPath = \"/home/jovyan/work/events-stream\"\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"tweet\", StringType)\n",
    "    .add(\"hiddentargetclue\", IntegerType)\n",
    "    .add(\"timestamp\", TimestampType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем стриминговый датасет и применяем к нему модель для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getPrediction01 = UserDefinedFunction(<function1>,IntegerType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n",
       "inputDF = [window: struct<start: timestamp, end: timestamp>, predicted_neg: bigint ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[window: struct<start: timestamp, end: timestamp>, predicted_neg: bigint ... 3 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Определяем udf для предсказания негативного (0) или позитивного (1) твита\n",
    "val getPrediction01 =\n",
    "    udf(\n",
    "        (prediction: org.apache.spark.ml.linalg.Vector) =>\n",
    "        if ( prediction(0) >= prediction(1) ) 0 else 1 // При равенстве будем склоняться к 0 :)\n",
    "    )\n",
    "\n",
    "val inputDF =\n",
    "    model.transform( // применяем модель для предсказания\n",
    "        spark\n",
    "        .readStream\n",
    "        .schema(dataSchema)\n",
    "        .json(inputStreamPath)\n",
    "        .withWatermark(\"timestamp\", \"60 seconds\") // задаем время устаревания данных в потоке пока что, на всякий случай, гораздо больше, чем предположительно нужно\n",
    "    )\n",
    "    .withColumn(\"prediction01\",getPrediction01($\"probability\")) // добавляем столбец с udf\n",
    "    .selectExpr(\n",
    "        \"window(timestamp, '10 seconds', '5 seconds') as window\", // определяем скользящее окно размером в 10 секунд со сдвигом в 5 секунд\n",
    "        \"case when prediction01 = 0 then 1 else 0 end as pred_neg\", // это основной столбец, требуемый в домашнем задании (предсказание к-ва негативных твитов в окне)\n",
    "        \"case when prediction01 = 1 then 1 else 0 end as pred_pos\", // дополнительный столбец для полноты картины :)\n",
    "        // В этом кейсе мы можем себе позволить вывести также и реальные метки негатива и позитива для сравнения с предсказанными :)\n",
    "        \"case when hiddentargetclue = 0 then 1 else 0 end as clue_neg\",\n",
    "        \"case when hiddentargetclue = 1 then 1 else 0 end as clue_pos\"\n",
    "    )\n",
    "    .groupBy($\"window\") // собираем к-во твитов в каждом окне\n",
    "    .agg( // и схлопываем \"шахматный\" отчет, суммируя соотв. столбцы\n",
    "        sum(\"pred_neg\").alias(\"predicted_neg\"),\n",
    "        sum(\"pred_pos\").alias(\"predicted_pos\"),\n",
    "        sum(\"clue_neg\").alias(\"clue_neg\"),\n",
    "        sum(\"clue_pos\").alias(\"clue_pos\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем потоковый запрос и стартуем его, обрабатывая батчами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch run # 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fRuns = 0\n",
       "stream = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4645ca42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4645ca42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|window                                    |predicted_neg|predicted_pos|clue_neg|clue_pos|\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|[2020-01-29 17:32:00, 2020-01-29 17:32:10]|11           |25           |12      |24      |\n",
      "|[2020-01-29 17:31:55, 2020-01-29 17:32:05]|15           |35           |16      |34      |\n",
      "|[2020-01-29 17:31:50, 2020-01-29 17:32:00]|8            |19           |7       |20      |\n",
      "|[2020-01-29 17:31:45, 2020-01-29 17:31:55]|10           |26           |11      |25      |\n",
      "|[2020-01-29 17:31:40, 2020-01-29 17:31:50]|9            |25           |13      |21      |\n",
      "|[2020-01-29 17:31:35, 2020-01-29 17:31:45]|5            |13           |7       |11      |\n",
      "|[2020-01-29 17:31:30, 2020-01-29 17:31:40]|2            |5            |2       |5       |\n",
      "|[2020-01-29 17:31:25, 2020-01-29 17:31:35]|5            |8            |7       |6       |\n",
      "|[2020-01-29 17:31:20, 2020-01-29 17:31:30]|13           |13           |14      |12      |\n",
      "|[2020-01-29 17:31:15, 2020-01-29 17:31:25]|14           |9            |14      |9       |\n",
      "|[2020-01-29 17:31:10, 2020-01-29 17:31:20]|13           |16           |16      |13      |\n",
      "|[2020-01-29 17:31:05, 2020-01-29 17:31:15]|14           |21           |18      |17      |\n",
      "|[2020-01-29 17:31:00, 2020-01-29 17:31:10]|14           |16           |16      |14      |\n",
      "|[2020-01-29 17:30:55, 2020-01-29 17:31:05]|11           |20           |15      |16      |\n",
      "|[2020-01-29 17:30:50, 2020-01-29 17:31:00]|12           |21           |16      |17      |\n",
      "|[2020-01-29 17:30:45, 2020-01-29 17:30:55]|15           |15           |15      |15      |\n",
      "|[2020-01-29 17:30:40, 2020-01-29 17:30:50]|15           |14           |12      |17      |\n",
      "|[2020-01-29 17:30:35, 2020-01-29 17:30:45]|8            |7            |5       |10      |\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "\n",
      "Batch run # 2\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|window                                    |predicted_neg|predicted_pos|clue_neg|clue_pos|\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|[2020-01-29 17:32:10, 2020-01-29 17:32:20]|4            |12           |9       |7       |\n",
      "|[2020-01-29 17:32:05, 2020-01-29 17:32:15]|12           |21           |19      |14      |\n",
      "|[2020-01-29 17:32:00, 2020-01-29 17:32:10]|19           |34           |22      |31      |\n",
      "|[2020-01-29 17:31:55, 2020-01-29 17:32:05]|15           |35           |16      |34      |\n",
      "|[2020-01-29 17:31:50, 2020-01-29 17:32:00]|8            |19           |7       |20      |\n",
      "|[2020-01-29 17:31:45, 2020-01-29 17:31:55]|10           |26           |11      |25      |\n",
      "|[2020-01-29 17:31:40, 2020-01-29 17:31:50]|9            |25           |13      |21      |\n",
      "|[2020-01-29 17:31:35, 2020-01-29 17:31:45]|5            |13           |7       |11      |\n",
      "|[2020-01-29 17:31:30, 2020-01-29 17:31:40]|2            |5            |2       |5       |\n",
      "|[2020-01-29 17:31:25, 2020-01-29 17:31:35]|5            |8            |7       |6       |\n",
      "|[2020-01-29 17:31:20, 2020-01-29 17:31:30]|13           |13           |14      |12      |\n",
      "|[2020-01-29 17:31:15, 2020-01-29 17:31:25]|14           |9            |14      |9       |\n",
      "|[2020-01-29 17:31:10, 2020-01-29 17:31:20]|13           |16           |16      |13      |\n",
      "|[2020-01-29 17:31:05, 2020-01-29 17:31:15]|14           |21           |18      |17      |\n",
      "|[2020-01-29 17:31:00, 2020-01-29 17:31:10]|14           |16           |16      |14      |\n",
      "|[2020-01-29 17:30:55, 2020-01-29 17:31:05]|11           |20           |15      |16      |\n",
      "|[2020-01-29 17:30:50, 2020-01-29 17:31:00]|12           |21           |16      |17      |\n",
      "|[2020-01-29 17:30:45, 2020-01-29 17:30:55]|15           |15           |15      |15      |\n",
      "|[2020-01-29 17:30:40, 2020-01-29 17:30:50]|15           |14           |12      |17      |\n",
      "|[2020-01-29 17:30:35, 2020-01-29 17:30:45]|8            |7            |5       |10      |\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "\n",
      "Batch run # 3\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|window                                    |predicted_neg|predicted_pos|clue_neg|clue_pos|\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|[2020-01-29 17:32:30, 2020-01-29 17:32:40]|5            |16           |11      |10      |\n",
      "|[2020-01-29 17:32:25, 2020-01-29 17:32:35]|7            |31           |20      |18      |\n",
      "|[2020-01-29 17:32:20, 2020-01-29 17:32:30]|7            |18           |15      |10      |\n",
      "|[2020-01-29 17:32:15, 2020-01-29 17:32:25]|5            |3            |6       |2       |\n",
      "|[2020-01-29 17:32:10, 2020-01-29 17:32:20]|4            |12           |9       |7       |\n",
      "|[2020-01-29 17:32:05, 2020-01-29 17:32:15]|12           |21           |19      |14      |\n",
      "|[2020-01-29 17:32:00, 2020-01-29 17:32:10]|19           |34           |22      |31      |\n",
      "|[2020-01-29 17:31:55, 2020-01-29 17:32:05]|15           |35           |16      |34      |\n",
      "|[2020-01-29 17:31:50, 2020-01-29 17:32:00]|8            |19           |7       |20      |\n",
      "|[2020-01-29 17:31:45, 2020-01-29 17:31:55]|10           |26           |11      |25      |\n",
      "|[2020-01-29 17:31:40, 2020-01-29 17:31:50]|9            |25           |13      |21      |\n",
      "|[2020-01-29 17:31:35, 2020-01-29 17:31:45]|5            |13           |7       |11      |\n",
      "|[2020-01-29 17:31:30, 2020-01-29 17:31:40]|2            |5            |2       |5       |\n",
      "|[2020-01-29 17:31:25, 2020-01-29 17:31:35]|5            |8            |7       |6       |\n",
      "|[2020-01-29 17:31:20, 2020-01-29 17:31:30]|13           |13           |14      |12      |\n",
      "|[2020-01-29 17:31:15, 2020-01-29 17:31:25]|14           |9            |14      |9       |\n",
      "|[2020-01-29 17:31:10, 2020-01-29 17:31:20]|13           |16           |16      |13      |\n",
      "|[2020-01-29 17:31:05, 2020-01-29 17:31:15]|14           |21           |18      |17      |\n",
      "|[2020-01-29 17:31:00, 2020-01-29 17:31:10]|14           |16           |16      |14      |\n",
      "|[2020-01-29 17:30:55, 2020-01-29 17:31:05]|11           |20           |15      |16      |\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Batch run # 4\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|window                                    |predicted_neg|predicted_pos|clue_neg|clue_pos|\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|[2020-01-29 17:32:40, 2020-01-29 17:32:50]|9            |15           |9       |15      |\n",
      "|[2020-01-29 17:32:35, 2020-01-29 17:32:45]|14           |28           |17      |25      |\n",
      "|[2020-01-29 17:32:30, 2020-01-29 17:32:40]|10           |29           |19      |20      |\n",
      "|[2020-01-29 17:32:25, 2020-01-29 17:32:35]|7            |31           |20      |18      |\n",
      "|[2020-01-29 17:32:20, 2020-01-29 17:32:30]|7            |18           |15      |10      |\n",
      "|[2020-01-29 17:32:15, 2020-01-29 17:32:25]|5            |3            |6       |2       |\n",
      "|[2020-01-29 17:32:10, 2020-01-29 17:32:20]|4            |12           |9       |7       |\n",
      "|[2020-01-29 17:32:05, 2020-01-29 17:32:15]|12           |21           |19      |14      |\n",
      "|[2020-01-29 17:32:00, 2020-01-29 17:32:10]|19           |34           |22      |31      |\n",
      "|[2020-01-29 17:31:55, 2020-01-29 17:32:05]|15           |35           |16      |34      |\n",
      "|[2020-01-29 17:31:50, 2020-01-29 17:32:00]|8            |19           |7       |20      |\n",
      "|[2020-01-29 17:31:45, 2020-01-29 17:31:55]|10           |26           |11      |25      |\n",
      "|[2020-01-29 17:31:40, 2020-01-29 17:31:50]|9            |25           |13      |21      |\n",
      "|[2020-01-29 17:31:35, 2020-01-29 17:31:45]|5            |13           |7       |11      |\n",
      "|[2020-01-29 17:31:30, 2020-01-29 17:31:40]|2            |5            |2       |5       |\n",
      "|[2020-01-29 17:31:25, 2020-01-29 17:31:35]|5            |8            |7       |6       |\n",
      "|[2020-01-29 17:31:20, 2020-01-29 17:31:30]|13           |13           |14      |12      |\n",
      "|[2020-01-29 17:31:15, 2020-01-29 17:31:25]|14           |9            |14      |9       |\n",
      "|[2020-01-29 17:31:10, 2020-01-29 17:31:20]|13           |16           |16      |13      |\n",
      "|[2020-01-29 17:31:05, 2020-01-29 17:31:15]|14           |21           |18      |17      |\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Batch run # 5\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|window                                    |predicted_neg|predicted_pos|clue_neg|clue_pos|\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "|[2020-01-29 17:32:55, 2020-01-29 17:33:05]|8            |9            |11      |6       |\n",
      "|[2020-01-29 17:32:50, 2020-01-29 17:33:00]|14           |18           |19      |13      |\n",
      "|[2020-01-29 17:32:45, 2020-01-29 17:32:55]|6            |9            |8       |7       |\n",
      "|[2020-01-29 17:32:40, 2020-01-29 17:32:50]|9            |15           |9       |15      |\n",
      "|[2020-01-29 17:32:35, 2020-01-29 17:32:45]|14           |28           |17      |25      |\n",
      "|[2020-01-29 17:32:30, 2020-01-29 17:32:40]|10           |29           |19      |20      |\n",
      "|[2020-01-29 17:32:25, 2020-01-29 17:32:35]|7            |31           |20      |18      |\n",
      "|[2020-01-29 17:32:20, 2020-01-29 17:32:30]|7            |18           |15      |10      |\n",
      "|[2020-01-29 17:32:15, 2020-01-29 17:32:25]|5            |3            |6       |2       |\n",
      "|[2020-01-29 17:32:10, 2020-01-29 17:32:20]|4            |12           |9       |7       |\n",
      "|[2020-01-29 17:32:05, 2020-01-29 17:32:15]|12           |21           |19      |14      |\n",
      "|[2020-01-29 17:32:00, 2020-01-29 17:32:10]|19           |34           |22      |31      |\n",
      "|[2020-01-29 17:31:55, 2020-01-29 17:32:05]|15           |35           |16      |34      |\n",
      "|[2020-01-29 17:31:50, 2020-01-29 17:32:00]|8            |19           |7       |20      |\n",
      "|[2020-01-29 17:31:45, 2020-01-29 17:31:55]|10           |26           |11      |25      |\n",
      "|[2020-01-29 17:31:40, 2020-01-29 17:31:50]|9            |25           |13      |21      |\n",
      "|[2020-01-29 17:31:35, 2020-01-29 17:31:45]|5            |13           |7       |11      |\n",
      "|[2020-01-29 17:31:30, 2020-01-29 17:31:40]|2            |5            |2       |5       |\n",
      "|[2020-01-29 17:31:25, 2020-01-29 17:31:35]|5            |8            |7       |6       |\n",
      "|[2020-01-29 17:31:20, 2020-01-29 17:31:30]|13           |13           |14      |12      |\n",
      "+------------------------------------------+-------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Batch run # 6\n",
      "Job 337 cancelled part of cancelled job group 9638d0e8-edd1-4767-a1d4-72fb0d5f1d92\n"
     ]
    }
   ],
   "source": [
    "var fRuns = 0\n",
    "// Микробатч для вывода результата предсказания\n",
    "// Выводится вероятность негативного твита и доп. стоблцы\n",
    "// В задании написано, что вероятность негатива - это последняя колонка, но она здесь вроде первая (в позиции 0)\n",
    "val stream = inputDF.writeStream.outputMode(\"complete\").foreachBatch {\n",
    "    (batchDF: DataFrame, batchId: Long) => {\n",
    "        try {\n",
    "            fRuns += 1\n",
    "            println(s\"Batch run # $fRuns\")\n",
    "            batchDF.orderBy(($\"window\").desc).show(false)\n",
    "        } catch {\n",
    "            case e:Throwable => {\n",
    "                println(e.getMessage)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Останов чтения потока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
